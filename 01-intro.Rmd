# Lecture 1 {#intro}

## Variable types

### Continuous variables

A variable is continuous there is a meaningful "distance" between values.

### Categorical variable

A variable is categorical if there is no meaningful "distance" between values.

### Censored variables

Censored variables are a subset of continuous variables

### Count variables

Count variables are a subset of continuous variables.

## Hypothesis testing

In science, we are interested in testing hypotheses. Statistics allows us to formally test our hypotheses.

In statistical testing we have a **null** hypothesis ($\text{H}_0$) and an **alternative** hypothesis ($\text{H}_1$). We assume the null hypothesis is true and try to find the probability of what we have observed (or something more extreme). If our observations are very unlikely (assuming the null hypothesis is true) then we reject the null hypothesis in favor of the alternative hypothesis.

For example:

$\text{H}_0$: It is summer

$\text{H}_1$: It is not summer

Our observed data for today is an average temperature of -20C today. Assuming it is summer, how likely is it that today's average temperature will be -20C? Not very likely! We therefore reject $\text{H}_0$ ("it is summer") in favor of $\text{H}_1$ ("it is not summer"). That is, we conclude that it is not summer today.

## Which method to use?

Deciding on the appropriate statistical method is fairly easy. You just look at the:

- Outcome (type and distribution)
- Exposure (type)
- Dependencies in the data

And then essentially use a flowchart.

## One sample t-test

A one sample t-test tests if the mean of a continuous variable differs from a specified value (generally zero)

$\text{H}_0: \mu = 180$

$\text{H}_1: \mu \ne 180$

Or rephrased:

$\text{H}_0$: The average height of men is equal to the 180cm

$\text{H}_1$: The average height of men is not equal to 180cm

#### Assumptions

Aim: test if the mean of a continuous variable differs from a specified value

Outcome: continuous variable, all observations independent, distributed as a Normal distribution

Exposure: Does not exist

#### Non-parametric equivalent

This is to be used when the Normal distribution assumption does not hold

## Two sample t-tests

### What is a two sample t-test?

A t-test tests if the mean of a continuous variable differs between two groups.

$\text{H}_0: \mu_0 = \mu_1$

$\text{H}_1: \mu_0 \ne \mu_1$

Or rephrased:

$\text{H}_0$: The average height of men is equal to the average height of women

$\text{H}_1$: The average height of men is not equal to the average height of women

There are two kinds of two-sample t-tests: paired and unpaired.

### Two-sample paired t-test

A paired t-test is a special case where we have $N$ participants, and each participant has two observations (generally "before experiment" and "after experiment"). We want to test if the mean of outcome variable differs between "after" and "before".

For example, in a weight-loss experiment, we have $N$ participants and we want to see if the average "after weight" is different from the average "before weight".

This is done by subtracting the outcome from one group ("before weight") from the outcome in the other group ("after weight") for each person ("difference in weight"), and then performing a one-sample t-test to see if the mean of this variable is different from zero. 

$\text{H}_0: \mu_{\text{after}-\text{before}} = 0$

$\text{H}_1: \mu_{\text{after}-\text{before}} \ne 0$

#### Assumptions

Aim: test if the mean of a continuous variable measured twice for each participant differs between "before" and "after"

Special preprocessing of data: for each participant subtract the "before" observation from the "after" observation

Outcome: ("after weight" minus "before weight") continuous variable, all observations within each group independent, distributed as a Normal distribution

Exposure: $\text{group}_\text{after}$ vs $\text{group}_\text{before}$

#### Non-parametric equivalent

Wilcoxon signed-rank test

### Two-sample unpaired t-test

An unpaired t-test is where we have two independent groups of $N_1$ and $N_2$ participants, and we want to test if the mean of the outcome variable differs between $\text{group}_1$ and $\text{group}_2$.

$\text{H}_0: \mu_0 = \mu_1$

$\text{H}_1: \mu_0 \ne \mu_1$

Or rephrased:

$\text{H}_0$: The average height of men is equal to the average height of women

$\text{H}_1$: The average height of men is not equal to the average height of women

#### Assumptions

Aim: test if the mean of a continuous variable differs between $\text{group}_1$ and $\text{group}_2$.

Outcome: continuous variable, all observations within each group independent, distributed as a Normal distribution

Exposure: $\text{group}_1$ vs $\text{group}_2$

#### Non-parametric equivalent

Mann–Whitney U test (also called the Mann–Whitney–Wilcoxon (MWW), Wilcoxon rank-sum test, or Wilcoxon–Mann–Whitney test)

## Identifying when non-parametric t-test equivalents should be used

Non-parametric t-test equivalents should be used when the Normality distribution fails.

## ANOVA

ANOVA

#### Assumptions

#### Non-parametric equivalent

Kruskal–Wallis test

## Identifying when linear regression should be used

#### Assumptions

Aim: test if the mean of a continuous variable differs between $\text{group}_1$ and $\text{group}_2$.

Outcome: continuous variable

Exposure:

- Continuous
- Binary (0 or 1)
- Categorical (0, 1, 2, ...)
- Count data

## Identifying the similarities between t-tests, ANOVA, and linear regression

t-tests are ANOVA with only two groups

t-tests are linear regressions with a binary (0/1) exposure

ANOVA is a lienar regression with a categorical exposure

## Identifying when logistic regression models should be used

- When you have a binary (0/1) outcome
- When you are doing a case-control study [case control studies can ONLY be analysed using logistic regression]

## Identifying when Poisson/negative binomial models should be used

When your outcome is count data

## Cox regression models should be used

When you have survival data

## Identifying when chi-squared/fisher’s exact test should be used

When you have a categorical outcome and a categorical exposure
